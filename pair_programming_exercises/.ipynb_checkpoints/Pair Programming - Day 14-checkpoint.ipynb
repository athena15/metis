{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're named Danny Kyung or Matthew Emes, it opens up the possibility of justifying your use of usernames such as [dank](https://github.com/dank) or [memes](https://github.com/memes).\n",
    "Your task is to find the longest word such that it satisfies the criteria - that is, it is a substring of the given string but not necessarily consecutively (we can call it a sparse substring). If there are multiple words of same maximum length, output all of them.\n",
    "You may use the the [Enable word list](http://norvig.com/ngrams/enable1.txt), or some other reasonable English word list. Every word in your output must appear in your word list.\n",
    "Formal Inputs & Outputs\n",
    "\n",
    "#### Input description\n",
    "```\n",
    "One string.\n",
    "```\n",
    "#### Example Inputs\n",
    "```\n",
    "Donald Knuth\n",
    "Alan Turing\n",
    "Claude Shannon\n",
    "```\n",
    "#### Output description\n",
    "```\n",
    "A single word (output the lengthiest word/words in case of multiple words satisfying the criteria)\n",
    "```\n",
    "#### Example outputs\n",
    "```\n",
    "Donut (because **Don**ald k**nut**h)\n",
    "Alanin, Anting\n",
    "Cannon\n",
    "```\n",
    "Note : Your outputs may differ from these outputs depending on the word list you are using\n",
    "\n",
    "#### Challenge Inputs\n",
    "```\n",
    "Ada Lovelace\n",
    "Haskell Curry\n",
    "**Your own name!**\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_df = pd.read_csv('http://norvig.com/ngrams/enable1.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = [x[0] for x in word_df.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aah'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list.append('aa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_usernames(s):\n",
    "    s = s.lower()\n",
    "    username_list = []\n",
    "        \n",
    "    for i in range(len(s), 0, -1):\n",
    "        sub_list = [''.join(x) for x in list(combinations(s, i))]\n",
    "        username_list.extend([x for x in sub_list if x in word_list])\n",
    "        if len(username_list) > 0:\n",
    "            break\n",
    "        \n",
    "    return set(username_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'donut'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_usernames('Donald Knuth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cannon', 'clades'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_usernames('Claude Shannon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bennet', 'rennet', 'rennin'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_username('Brenner Heintz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kerfed'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_usernames('Kendra Frederick')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'retore'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_usernames('Roberto Reif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adherer'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_usernames('Chad Scherrer')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
